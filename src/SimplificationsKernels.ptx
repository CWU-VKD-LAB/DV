//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35059454
// Cuda compilation tools, release 12.6, V12.6.85
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	removeUselessHelper

.visible .entry removeUselessHelper(
	.param .u64 removeUselessHelper_param_0,
	.param .u64 removeUselessHelper_param_1,
	.param .u64 removeUselessHelper_param_2,
	.param .u32 removeUselessHelper_param_3,
	.param .u64 removeUselessHelper_param_4,
	.param .u32 removeUselessHelper_param_5,
	.param .u64 removeUselessHelper_param_6,
	.param .u64 removeUselessHelper_param_7,
	.param .u32 removeUselessHelper_param_8,
	.param .u64 removeUselessHelper_param_9,
	.param .u32 removeUselessHelper_param_10,
	.param .u64 removeUselessHelper_param_11,
	.param .u32 removeUselessHelper_param_12
)
{
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<86>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<298>;


	ld.param.u64 	%rd170, [removeUselessHelper_param_0];
	ld.param.u64 	%rd171, [removeUselessHelper_param_1];
	ld.param.u32 	%r47, [removeUselessHelper_param_5];
	ld.param.u64 	%rd172, [removeUselessHelper_param_7];
	ld.param.u32 	%r45, [removeUselessHelper_param_8];
	cvta.to.global.u64 	%rd1, %rd172;
	cvta.to.global.u64 	%rd2, %rd171;
	cvta.to.global.u64 	%rd3, %rd170;
	mov.u32 	%r48, %ntid.x;
	mov.u32 	%r49, %ctaid.x;
	mov.u32 	%r50, %tid.x;
	mad.lo.s32 	%r1, %r49, %r48, %r50;
	setp.ge.s32 	%p1, %r1, %r47;
	@%p1 bra 	$L__BB0_70;

	setp.lt.s32 	%p2, %r45, 1;
	@%p2 bra 	$L__BB0_70;

	mov.u32 	%r73, %tid.x;
	mov.u32 	%r72, %ntid.x;
	mov.u32 	%r71, %ctaid.x;
	mad.lo.s32 	%r70, %r71, %r72, %r73;
	ld.param.u32 	%r69, [removeUselessHelper_param_10];
	ld.param.u64 	%rd212, [removeUselessHelper_param_4];
	cvt.s64.s32 	%rd4, %r70;
	cvta.to.global.u64 	%rd173, %rd212;
	mul.wide.s32 	%rd174, %r70, 4;
	add.s64 	%rd5, %rd173, %rd174;
	mul.lo.s32 	%r2, %r69, %r45;
	setp.gt.s32 	%p3, %r2, 0;
	mul.lo.s32 	%r3, %r70, %r45;
	@%p3 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_3;

$L__BB0_29:
	ld.param.u64 	%rd213, [removeUselessHelper_param_9];
	ld.param.u64 	%rd211, [removeUselessHelper_param_11];
	ld.param.u64 	%rd210, [removeUselessHelper_param_6];
	cvta.to.global.u64 	%rd189, %rd210;
	shl.b64 	%rd190, %rd4, 2;
	add.s64 	%rd191, %rd189, %rd190;
	ld.global.u32 	%r57, [%rd191];
	cvta.to.global.u64 	%rd192, %rd211;
	mul.wide.s32 	%rd193, %r57, 4;
	add.s64 	%rd73, %rd192, %rd193;
	cvta.to.global.u64 	%rd74, %rd213;
	mov.u32 	%r56, 0;
	mov.u32 	%r78, %r56;

$L__BB0_30:
	ld.global.u32 	%r20, [%rd5];
	mul.wide.s32 	%rd194, %r20, 8;
	add.s64 	%rd295, %rd3, %rd194;
	add.s64 	%rd297, %rd2, %rd194;
	ld.global.u32 	%r21, [%rd5+4];
	mul.wide.s32 	%rd195, %r21, 8;
	add.s64 	%rd77, %rd3, %rd195;
	ld.global.u32 	%r59, [%rd73];
	mul.lo.s32 	%r22, %r59, %r45;
	ld.global.u32 	%r60, [%rd73+4];
	mul.lo.s32 	%r23, %r60, %r45;
	mov.u32 	%r79, %r56;

$L__BB0_31:
	setp.ge.s32 	%p20, %r79, %r22;
	setp.lt.s32 	%p21, %r79, %r23;
	and.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB0_39;

	setp.ge.s32 	%p23, %r20, %r21;
	@%p23 bra 	$L__BB0_69;

	mov.u32 	%r80, 0;
	mov.u64 	%rd267, %rd297;
	mov.u64 	%rd265, %rd295;
	mov.u64 	%rd266, %rd295;

$L__BB0_34:
	ld.global.f64 	%fd3, [%rd266];
	cvt.rzi.s32.f64 	%r26, %fd3;
	setp.eq.s32 	%p24, %r80, %r78;
	@%p24 bra 	$L__BB0_53;
	bra.uni 	$L__BB0_35;

$L__BB0_53:
	add.s64 	%rd265, %rd265, 8;
	add.s64 	%rd266, %rd266, 8;
	add.s64 	%rd267, %rd267, 8;
	setp.lt.s32 	%p30, %r26, 1;
	setp.ge.u64 	%p31, %rd265, %rd77;
	or.pred  	%p32, %p31, %p30;
	@%p32 bra 	$L__BB0_56;

	mov.u32 	%r82, 0;

$L__BB0_55:
	add.s64 	%rd266, %rd266, 8;
	add.s64 	%rd267, %rd267, 8;
	add.s32 	%r82, %r82, 1;
	setp.lt.s32 	%p33, %r82, %r26;
	add.s64 	%rd265, %rd265, 8;
	setp.lt.u64 	%p34, %rd265, %rd77;
	and.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB0_55;
	bra.uni 	$L__BB0_56;

$L__BB0_35:
	setp.lt.s32 	%p25, %r26, 1;
	@%p25 bra 	$L__BB0_39;

	add.s32 	%r63, %r80, %r79;
	mul.wide.s32 	%rd196, %r63, 8;
	add.s64 	%rd197, %rd74, %rd196;
	ld.global.f64 	%fd1, [%rd197];
	add.s64 	%rd267, %rd267, 16;
	add.s64 	%rd265, %rd265, 16;
	add.s64 	%rd266, %rd266, 16;
	mov.u32 	%r81, 0;

$L__BB0_37:
	ld.global.f64 	%fd4, [%rd267+-8];
	setp.le.f64 	%p26, %fd1, %fd4;
	ld.global.f64 	%fd5, [%rd266+-8];
	setp.ge.f64 	%p27, %fd1, %fd5;
	and.pred  	%p28, %p26, %p27;
	add.s32 	%r81, %r81, 1;
	@%p28 bra 	$L__BB0_56;

	add.s64 	%rd267, %rd267, 8;
	add.s64 	%rd265, %rd265, 8;
	add.s64 	%rd266, %rd266, 8;
	setp.lt.s32 	%p29, %r81, %r26;
	@%p29 bra 	$L__BB0_37;
	bra.uni 	$L__BB0_39;

$L__BB0_56:
	add.s32 	%r80, %r80, 1;
	setp.lt.u64 	%p36, %rd265, %rd77;
	@%p36 bra 	$L__BB0_34;
	bra.uni 	$L__BB0_69;

$L__BB0_39:
	add.s32 	%r79, %r79, %r45;
	setp.lt.s32 	%p37, %r79, %r2;
	@%p37 bra 	$L__BB0_31;

	setp.ge.s32 	%p38, %r20, %r21;
	@%p38 bra 	$L__BB0_68;

	mov.u32 	%r83, 0;
	mov.u64 	%rd296, %rd295;

$L__BB0_42:
	mov.u64 	%rd273, %rd296;
	mov.u64 	%rd272, %rd295;
	mov.u64 	%rd271, %rd297;
	ld.global.f64 	%fd6, [%rd273];
	cvt.rzi.s32.f64 	%r34, %fd6;
	add.s64 	%rd296, %rd273, 8;
	add.s64 	%rd297, %rd271, 8;
	setp.eq.s32 	%p39, %r83, %r78;
	@%p39 bra 	$L__BB0_57;
	bra.uni 	$L__BB0_43;

$L__BB0_57:
	setp.lt.s32 	%p46, %r34, 1;
	add.s64 	%rd295, %rd272, 8;
	@%p46 bra 	$L__BB0_67;

	add.s64 	%rd291, %rd273, 8;
	add.s64 	%rd289, %rd271, 8;
	add.s32 	%r67, %r34, -1;
	and.b32  	%r39, %r34, 3;
	setp.lt.u32 	%p47, %r67, 3;
	add.s64 	%rd290, %rd272, 8;
	@%p47 bra 	$L__BB0_62;

	add.s64 	%rd296, %rd273, 8;
	add.s64 	%rd297, %rd271, 8;
	sub.s32 	%r85, %r34, %r39;

$L__BB0_60:
	mov.u64 	%rd139, %rd272;
	mov.u64 	%rd200, 0;
	st.global.u64 	[%rd296], %rd200;
	mov.u64 	%rd201, 4607182418800017408;
	st.global.u64 	[%rd297], %rd201;
	st.global.u64 	[%rd296+8], %rd200;
	st.global.u64 	[%rd297+8], %rd201;
	st.global.u64 	[%rd296+16], %rd200;
	st.global.u64 	[%rd297+16], %rd201;
	add.s64 	%rd272, %rd139, 32;
	st.global.u64 	[%rd296+24], %rd200;
	st.global.u64 	[%rd297+24], %rd201;
	add.s64 	%rd296, %rd296, 32;
	add.s64 	%rd297, %rd297, 32;
	add.s32 	%r85, %r85, -4;
	setp.ne.s32 	%p48, %r85, 0;
	@%p48 bra 	$L__BB0_60;

	add.s64 	%rd292, %rd139, 32;
	add.s64 	%rd290, %rd139, 40;
	mov.u64 	%rd289, %rd297;
	mov.u64 	%rd291, %rd296;

$L__BB0_62:
	setp.eq.s32 	%p49, %r39, 0;
	@%p49 bra 	$L__BB0_66;

	mov.u64 	%rd202, 0;
	st.global.u64 	[%rd291], %rd202;
	mov.u64 	%rd203, 4607182418800017408;
	st.global.u64 	[%rd289], %rd203;
	add.s64 	%rd296, %rd291, 8;
	add.s64 	%rd297, %rd289, 8;
	setp.eq.s32 	%p50, %r39, 1;
	mov.u64 	%rd292, %rd290;
	@%p50 bra 	$L__BB0_66;

	add.s64 	%rd292, %rd290, 8;
	st.global.u64 	[%rd291+8], %rd202;
	st.global.u64 	[%rd289+8], %rd203;
	add.s64 	%rd296, %rd291, 16;
	add.s64 	%rd297, %rd289, 16;
	setp.eq.s32 	%p51, %r39, 2;
	@%p51 bra 	$L__BB0_66;

	add.s64 	%rd292, %rd290, 16;
	mov.u64 	%rd206, 0;
	st.global.u64 	[%rd291+16], %rd206;
	mov.u64 	%rd207, 4607182418800017408;
	st.global.u64 	[%rd289+16], %rd207;
	add.s64 	%rd296, %rd291, 24;
	add.s64 	%rd297, %rd289, 24;

$L__BB0_66:
	add.s64 	%rd295, %rd292, 8;
	bra.uni 	$L__BB0_67;

$L__BB0_43:
	setp.lt.s32 	%p40, %r34, 1;
	add.s64 	%rd295, %rd272, 8;
	@%p40 bra 	$L__BB0_67;

	add.s64 	%rd279, %rd273, 8;
	add.s64 	%rd277, %rd271, 8;
	add.s32 	%r66, %r34, -1;
	and.b32  	%r35, %r34, 3;
	setp.lt.u32 	%p41, %r66, 3;
	add.s64 	%rd278, %rd272, 8;
	@%p41 bra 	$L__BB0_48;

	sub.s32 	%r84, %r34, %r35;

$L__BB0_46:
	mov.u64 	%rd111, %rd273;
	mov.u64 	%rd110, %rd272;
	mov.u64 	%rd109, %rd271;
	add.s64 	%rd272, %rd110, 32;
	add.s32 	%r84, %r84, -4;
	setp.ne.s32 	%p42, %r84, 0;
	add.s64 	%rd271, %rd109, 32;
	add.s64 	%rd273, %rd111, 32;
	@%p42 bra 	$L__BB0_46;

	add.s64 	%rd280, %rd110, 32;
	add.s64 	%rd296, %rd111, 40;
	add.s64 	%rd297, %rd109, 40;
	add.s64 	%rd278, %rd110, 40;
	mov.u64 	%rd277, %rd297;
	mov.u64 	%rd279, %rd296;

$L__BB0_48:
	setp.eq.s32 	%p43, %r35, 0;
	@%p43 bra 	$L__BB0_52;

	add.s64 	%rd296, %rd279, 8;
	add.s64 	%rd297, %rd277, 8;
	setp.eq.s32 	%p44, %r35, 1;
	mov.u64 	%rd280, %rd278;
	@%p44 bra 	$L__BB0_52;

	add.s64 	%rd280, %rd278, 8;
	add.s64 	%rd296, %rd279, 16;
	add.s64 	%rd297, %rd277, 16;
	setp.eq.s32 	%p45, %r35, 2;
	@%p45 bra 	$L__BB0_52;

	add.s64 	%rd280, %rd278, 16;
	add.s64 	%rd296, %rd279, 24;
	add.s64 	%rd297, %rd277, 24;

$L__BB0_52:
	add.s64 	%rd295, %rd280, 8;

$L__BB0_67:
	add.s32 	%r83, %r83, 1;
	setp.lt.u64 	%p52, %rd295, %rd77;
	@%p52 bra 	$L__BB0_42;

$L__BB0_68:
	add.s32 	%r68, %r78, %r3;
	cvt.s64.s32 	%rd208, %r68;
	add.s64 	%rd209, %rd1, %rd208;
	mov.u16 	%rs2, 1;
	st.global.u8 	[%rd209], %rs2;

$L__BB0_69:
	add.s32 	%r78, %r78, 1;
	setp.lt.s32 	%p53, %r78, %r45;
	@%p53 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_70;

$L__BB0_3:
	mov.u32 	%r74, 0;

$L__BB0_4:
	ld.global.u32 	%r5, [%rd5+4];
	ld.global.u32 	%r6, [%rd5];
	setp.ge.s32 	%p4, %r6, %r5;
	@%p4 bra 	$L__BB0_28;

	mul.wide.s32 	%rd175, %r6, 8;
	add.s64 	%rd253, %rd3, %rd175;
	add.s64 	%rd255, %rd2, %rd175;
	mul.wide.s32 	%rd176, %r5, 8;
	add.s64 	%rd8, %rd3, %rd176;
	mov.u32 	%r75, 0;
	mov.u64 	%rd254, %rd253;

$L__BB0_6:
	mov.u64 	%rd231, %rd254;
	mov.u64 	%rd238, %rd253;
	mov.u64 	%rd229, %rd255;
	ld.global.f64 	%fd2, [%rd231];
	cvt.rzi.s32.f64 	%r8, %fd2;
	add.s64 	%rd254, %rd231, 8;
	add.s64 	%rd255, %rd229, 8;
	setp.eq.s32 	%p5, %r75, %r74;
	@%p5 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_7;

$L__BB0_17:
	setp.lt.s32 	%p12, %r8, 1;
	add.s64 	%rd253, %rd238, 8;
	@%p12 bra 	$L__BB0_27;

	add.s32 	%r54, %r8, -1;
	and.b32  	%r13, %r8, 3;
	setp.lt.u32 	%p13, %r54, 3;
	add.s64 	%rd248, %rd238, 8;
	mov.u64 	%rd247, %rd255;
	mov.u64 	%rd249, %rd254;
	@%p13 bra 	$L__BB0_22;

	sub.s32 	%r77, %r8, %r13;

$L__BB0_20:
	mov.u64 	%rd46, %rd238;
	mov.u64 	%rd179, 0;
	st.global.u64 	[%rd254], %rd179;
	mov.u64 	%rd180, 4607182418800017408;
	st.global.u64 	[%rd255], %rd180;
	st.global.u64 	[%rd254+8], %rd179;
	st.global.u64 	[%rd255+8], %rd180;
	st.global.u64 	[%rd254+16], %rd179;
	st.global.u64 	[%rd255+16], %rd180;
	add.s64 	%rd238, %rd46, 32;
	st.global.u64 	[%rd254+24], %rd179;
	st.global.u64 	[%rd255+24], %rd180;
	add.s64 	%rd254, %rd254, 32;
	add.s64 	%rd255, %rd255, 32;
	add.s32 	%r77, %r77, -4;
	setp.ne.s32 	%p14, %r77, 0;
	@%p14 bra 	$L__BB0_20;

	add.s64 	%rd248, %rd46, 40;
	mov.u64 	%rd247, %rd255;
	mov.u64 	%rd249, %rd254;

$L__BB0_22:
	setp.eq.s32 	%p15, %r13, 0;
	@%p15 bra 	$L__BB0_26;

	mov.u64 	%rd181, 0;
	st.global.u64 	[%rd249], %rd181;
	mov.u64 	%rd182, 4607182418800017408;
	st.global.u64 	[%rd247], %rd182;
	add.s64 	%rd254, %rd249, 8;
	add.s64 	%rd255, %rd247, 8;
	setp.eq.s32 	%p16, %r13, 1;
	mov.u64 	%rd238, %rd248;
	@%p16 bra 	$L__BB0_26;

	add.s64 	%rd238, %rd248, 8;
	st.global.u64 	[%rd249+8], %rd181;
	st.global.u64 	[%rd247+8], %rd182;
	add.s64 	%rd254, %rd249, 16;
	add.s64 	%rd255, %rd247, 16;
	setp.eq.s32 	%p17, %r13, 2;
	@%p17 bra 	$L__BB0_26;

	add.s64 	%rd238, %rd248, 16;
	mov.u64 	%rd185, 0;
	st.global.u64 	[%rd249+16], %rd185;
	mov.u64 	%rd186, 4607182418800017408;
	st.global.u64 	[%rd247+16], %rd186;
	add.s64 	%rd254, %rd249, 24;
	add.s64 	%rd255, %rd247, 24;

$L__BB0_26:
	add.s64 	%rd253, %rd238, 8;
	bra.uni 	$L__BB0_27;

$L__BB0_7:
	setp.lt.s32 	%p6, %r8, 1;
	add.s64 	%rd253, %rd238, 8;
	@%p6 bra 	$L__BB0_27;

	add.s32 	%r53, %r8, -1;
	and.b32  	%r9, %r8, 3;
	setp.lt.u32 	%p7, %r53, 3;
	add.s64 	%rd236, %rd238, 8;
	mov.u64 	%rd235, %rd255;
	mov.u64 	%rd237, %rd254;
	@%p7 bra 	$L__BB0_12;

	sub.s32 	%r76, %r8, %r9;

$L__BB0_10:
	mov.u64 	%rd18, %rd231;
	mov.u64 	%rd17, %rd238;
	mov.u64 	%rd16, %rd229;
	add.s64 	%rd238, %rd17, 32;
	add.s32 	%r76, %r76, -4;
	setp.ne.s32 	%p8, %r76, 0;
	add.s64 	%rd229, %rd16, 32;
	add.s64 	%rd231, %rd18, 32;
	@%p8 bra 	$L__BB0_10;

	add.s64 	%rd254, %rd18, 40;
	add.s64 	%rd255, %rd16, 40;
	add.s64 	%rd236, %rd17, 40;
	mov.u64 	%rd235, %rd255;
	mov.u64 	%rd237, %rd254;

$L__BB0_12:
	setp.eq.s32 	%p9, %r9, 0;
	@%p9 bra 	$L__BB0_16;

	add.s64 	%rd254, %rd237, 8;
	add.s64 	%rd255, %rd235, 8;
	setp.eq.s32 	%p10, %r9, 1;
	mov.u64 	%rd238, %rd236;
	@%p10 bra 	$L__BB0_16;

	add.s64 	%rd238, %rd236, 8;
	add.s64 	%rd254, %rd237, 16;
	add.s64 	%rd255, %rd235, 16;
	setp.eq.s32 	%p11, %r9, 2;
	@%p11 bra 	$L__BB0_16;

	add.s64 	%rd238, %rd236, 16;
	add.s64 	%rd254, %rd237, 24;
	add.s64 	%rd255, %rd235, 24;

$L__BB0_16:
	add.s64 	%rd253, %rd238, 8;

$L__BB0_27:
	add.s32 	%r75, %r75, 1;
	setp.lt.u64 	%p18, %rd253, %rd8;
	@%p18 bra 	$L__BB0_6;

$L__BB0_28:
	add.s32 	%r55, %r74, %r3;
	cvt.s64.s32 	%rd187, %r55;
	add.s64 	%rd188, %rd1, %rd187;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd188], %rs1;
	add.s32 	%r74, %r74, 1;
	setp.lt.s32 	%p19, %r74, %r45;
	@%p19 bra 	$L__BB0_4;

$L__BB0_70:
	ret;

}

